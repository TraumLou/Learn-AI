# 介绍
这个目录是从深度之眼的pytorch课程中学习并整理的学习笔记

- [课程页面入口](https://ai.deepshare.net/detail/p_5df0ad9a09d37_qYqVmt85/6)
- [课程代码github](https://github.com/JansonYuan/Pytorch-Camp)
- [作业讲解代码](https://github.com/greebear/pytorch-learning)
- 课程所有代码汇总中配套数据百度网盘地址：https://pan.baidu.com/s/1mA8wSCLnKphByzvHBzc9Pw 
提取码：g5ym
- 课程所有课件汇总百度网盘地址：https://pan.baidu.com/s/1svt3lbDgNGixk5lKM1zfig 
提取码：9j2f

# 目录笔记

[Week1 Pytorch基础概念](https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week1.ipynb)
- Pytorch简介及环境配置
- Pytorch基础数据结构——张量
- 张量操作与线性回归
- 计算图与动态图机制
- autograd与逻辑回归

[Week2 PyTorch数据处理](https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week2.ipynb)
- 数据读取机制DataLoader与Dataset
- 数据预处理transforms模块机制
- 二十二种transforms数据预处理方法
- 学会自定义transforms方法

[Week3 PyTorch模型搭建](https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week3.ipynb)
- nn.Module与网络模型构建步骤
- 模型容器与AlexNet构建
- 网络层中的卷积层
- 网络层中的池化层、全连接层和激活函数层

[Week4 PyTorch损失优化](https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week4.ipynb)
- 权值初始化
- 损失函数（一）
- Pytorch的14种损失函数
- 优化器optimizer的概念
- torch.optim.SGD

Week5 PyTorch训练过程
- 学习率调整
- TensorBoard简介与安装
- TensorBoard使用（一）
- TensorBoard使用（二）
- hook函数与CAM

Week6 PyTorch的正则化
- weight_decay
- dropout
- Batch Normalization
- Layer Normalization、Instance
- Normalization和Group Normalization

Week7 PyTorch训练技巧
- 模型保存与加载
- Finetune
- GPU的使用
- Pytorch中常见报错

Week8、9 PyTorch深度体验
- 图像分类一瞥
- 图像分割一瞥
- 目标检测一瞥（上）
- 目标检测一瞥（下）
- 对抗生成网络一瞥
- 循环神经网络一瞥