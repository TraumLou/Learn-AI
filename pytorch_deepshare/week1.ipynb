{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.张量简介与创建\n",
    "\n",
    "## Tensor概念\n",
    "\n",
    "Q:张量是什么？\n",
    "- 一个多维数组，它是标量、向量、矩阵的高维拓展\n",
    "- ![](http://anki190912.xuexihaike.com/20200918142143.png?imageView2/2/h/150)\n",
    "\n",
    "Q:Pytorch中的Variable是什么？与Tensor的关系是什么？\n",
    "- Variable是torch.autograd中的数据类型主要用于封装Tensor，进行自动求导\n",
    "- data:被包装的Tensor\n",
    "- grad:data的梯度\n",
    "- grad_fn:创建Tensor的Function，是自动求导的关键\n",
    "- requires_grad:指示是否需要梯度\n",
    "- is_leaf:指示是否是叶子结点（张量）\n",
    "- ![](http://anki190912.xuexihaike.com/20200918143346.png?imageView2/2/w/200)\n",
    "\n",
    "Q:Pytorch中的Tensor是什么？\n",
    "- PyTorch 0.4.0开始，Variable并入Tensor\n",
    "- dtype: 张量的数据类型，如torch.FloatTensor, torch.cuda.FloatTensor\n",
    "- shape: 张量的形状，如（64，3， 224， 224）\n",
    "- device: 张量所在设备，GPU/CPU，是加速的关键\n",
    "- ![](http://anki190912.xuexihaike.com/20200918143722.png?imageView2/2/h/100)\n",
    "\n",
    "## Tensor创建\n",
    "\n",
    "Q:Tensor的函数原型是怎样？\n",
    "- torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)\n",
    "- 功能：从data创建tensor\n",
    "- data: 数据，可以是list，numpy\n",
    "- dtype: 数据类型，默认与data一致\n",
    "- device: 所在设备，cuda/cpu\n",
    "- requires_grad: 是否需要梯度\n",
    "- pin_memory:是否存于锁页内存\n",
    "\n",
    "Q:通过torch.tensor创建Tensor的代码是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "ndarray的数据类型: float64\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "arr = np.ones((3, 3))\n",
    "print(arr)\n",
    "print('ndarray的数据类型:', arr.dtype)\n",
    "\n",
    "t = torch.tensor(arr)\n",
    "print(t)\n",
    "\n",
    "# 放到gpu上\n",
    "t = torch.tensor(arr, device='cuda')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何通过torch.from_numpy创建张量？\n",
    "- 函数原型：torch.from_numpy(ndarray)\n",
    "- 功能：从numpy创建tensor\n",
    "- 注意事项：从torch.from_numpy创建的tensor于原ndarray共享内存，当修改其中一个的数据，另外一个也将会被改动\n",
    "- ![](http://anki190912.xuexihaike.com/20200918151039.png?imageView2/2/h/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy array:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "修改arr:\n",
      "numpy array:\n",
      "[[0 2 3]\n",
      " [4 5 6]]\n",
      "tensor:\n",
      "tensor([[0, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "修改tensor:\n",
      "numpy array:\n",
      "[[  0   2   3]\n",
      " [  4 -10   6]]\n",
      "tensor:\n",
      "tensor([[  0,   2,   3],\n",
      "        [  4, -10,   6]])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "t = torch.from_numpy(arr)\n",
    "print(\"numpy array:\")\n",
    "print(arr)\n",
    "print(\"tensor:\")\n",
    "print(t)\n",
    "\n",
    "print(\"修改arr:\")\n",
    "arr[0, 0] = 0\n",
    "print(\"numpy array:\")\n",
    "print(arr)\n",
    "print(\"tensor:\")\n",
    "print(t)\n",
    "\n",
    "print(\"修改tensor:\")\n",
    "arr[1, 1] = -10\n",
    "print(\"numpy array:\")\n",
    "print(arr)\n",
    "print(\"tensor:\")\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何通过torch.zeros或torch.ones创建张量？\n",
    "- 函数原型：torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "- 函数原型：torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "- 功能：依size创建全0张量和全1\n",
    "- size:张量的形状\n",
    "- out:输出的张量，貌似其原始类型必须为tensor，通过out得到的和返回值得到的是完全一样的，相当于赋值\n",
    "- layout:内存中布局形式，有strided,sparse_coo等\n",
    "- device:所在设备,gpu/cpu\n",
    "- requires_grad: 是否需要梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "140055270334752 140055270334752 True\n"
     ]
    }
   ],
   "source": [
    "out_t = torch.tensor([1])\n",
    "t = torch.zeros((3,3), out=out_t)\n",
    "print(t)\n",
    "print(out_t)\n",
    "print(id(t), id(out_t), id(t) == id(out_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何通过torch.zeros_like或torch.ones_like创建张量？\n",
    "- 函数原型：torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False)\n",
    "- 函数原型：torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False)\n",
    "- 功能：依input形状创建全0张量或全1，input是一个tensor类型\n",
    "- input:创建与input同形状的全0张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.empty(2,3)\n",
    "print(torch.zeros_like(t))\n",
    "print(torch.ones_like(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何通过torch.full创建张量？\n",
    "- torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "- torch.full_like(input, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format)\n",
    "- 功能：创建全等张量\n",
    "- size: 张量的形状，如（3,3）\n",
    "- fill_value: 张量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 8., 8.],\n",
       "        [8., 8., 8.],\n",
       "        [8., 8., 8.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((3,3), 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何通过torch.arange创建等差数列的1维张量？\n",
    "- 函数原型：torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "- 功能：创建等差为1的张量\n",
    "- 注意事项：数值区间为[start, end)\n",
    "- start: 数列起始值\n",
    "- end: 数列“结束值”\n",
    "- step: 数列公差，默认为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 6, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(2,10,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何通过torch.linspace创建均分数列张量\n",
    "- 函数原型：torch.linspace(start=0, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "- 功能：创建均分的1维张量\n",
    "- 注意事项：数值区间为[start, end]\n",
    "- start: 数列起始值\n",
    "- end: 数列结束值\n",
    "- steps: 数列长度\n",
    "- 步长为：(end-start)/(steps-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0000,  3.3333,  4.6667,  6.0000,  7.3333,  8.6667, 10.0000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(2, 10, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何通过torch.logspace创建对数均分的1维张量？\n",
    "- 函数原型：torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "- 功能：创建对数均分的1维张量\n",
    "- 注意事项：长度为steps，底为base\n",
    "- base: 对数函数的低，默认为10\n",
    "\n",
    "Q:如何通过torch.eye创建单位对角矩阵？\n",
    "- 函数原型：torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "- 功能：创建单位对角矩阵（2维张量）\n",
    "- 注意事项：默认为方阵\n",
    "- n: 矩阵行数\n",
    "- m: 矩阵列数\n",
    "\n",
    "Q:如何通过torch.normal生成正态分布的张量？\n",
    "- 函数原型：torch.normal(mean, std, *, generator=None, out=None)\n",
    "- 功能：生成正态分布（高斯分布）\n",
    "- mean: 均值\n",
    "- std: 标准差\n",
    "- 因mean和std可以分别为标量和张量，有4种不同的组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:tensor([1., 2., 3., 4.])\n",
      "std:tensor([1., 2., 3., 4.])\n",
      "tensor([ 1.3656,  2.6678, -0.7582, 10.2440])\n",
      "\n",
      "tensor([-1.4877, -0.6809, -1.2212, -1.1693])\n",
      "\n",
      "mean:tensor([1., 2., 3., 4.])\n",
      "std:1\n",
      "tensor([-0.8548,  3.4765,  1.8932,  3.9761])\n"
     ]
    }
   ],
   "source": [
    "# mean：张量 std: 张量\n",
    "# 其中t[i]是从mean[i],std[i]的标准正态分布中采样得来\n",
    "mean = torch.arange(1, 5, dtype=torch.float)\n",
    "std = torch.arange(1, 5, dtype=torch.float)\n",
    "t = torch.normal(mean, std)\n",
    "print(\"mean:{}\\nstd:{}\".format(mean, std))\n",
    "print(t)\n",
    "print()\n",
    "\n",
    "# mean：标量 std: 标量，此时要指定size大小\n",
    "t_normal = torch.normal(0., 1., size=(4,))\n",
    "print(t_normal)\n",
    "print()\n",
    "\n",
    "# mean：张量 std: 标量\n",
    "mean = torch.arange(1, 5, dtype=torch.float)\n",
    "std = 1\n",
    "t_normal = torch.normal(mean, std)\n",
    "print(\"mean:{}\\nstd:{}\".format(mean, std))\n",
    "print(t_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何创建标准正态分布的张量？\n",
    "- torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n",
    "- torch.randn_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor\n",
    "- size:张量的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3111, -0.0802,  0.1347,  1.2559])\n",
      "tensor([[-1.3748,  1.7157, -0.4223],\n",
      "        [ 1.1199, -1.3477,  0.6594]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(4))\n",
    "print(torch.randn(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:如何生成均匀分布和整数均匀分布的张量？\n",
    "- 在[0,1)区间上，生成均匀分布\n",
    "- torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n",
    "- torch.rand_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor\n",
    "- 在[low, high)区间生成整数均匀分布\n",
    "- torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n",
    "- torch.randint_like(input, low=0, high, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor\n",
    "- 其中size是张量形状\n",
    "\n",
    "Q:如何生成从0到n-1的随机排列？\n",
    "- torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False) → LongTensor\n",
    "- n是张量的长度\n",
    "- 经常用于生成乱序索引\n",
    "\n",
    "Q:如何生成一个伯努利分布的张量？\n",
    "- torch.bernoulli(input, *, generator=None, out=None) → Tensor\n",
    "- 以input为概率，生成伯努利分布（0-1分布，两点分布）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.张量操作与线性回归\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
